{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tF5oVtBA8Ttk"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.content/competitiondata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "2gToprcS4bUe",
        "outputId": "0e4d1786-8e63-4c43-8a2b-829640c5059d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d1e4bf5c-f721-47fb-8f30-fe95898dcd6f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d1e4bf5c-f721-47fb-8f30-fe95898dcd6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading deep-learning-mini-project-spring-24-nyu.zip to /content\n",
            " 92% 173M/189M [00:02<00:00, 86.9MB/s]\n",
            "100% 189M/189M [00:02<00:00, 85.8MB/s]\n",
            "Archive:  deep-learning-mini-project-spring-24-nyu.zip\n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/batches.meta  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/data_batch_1  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/data_batch_2  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/data_batch_3  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/data_batch_4  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/data_batch_5  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/readme.html  \n",
            "  inflating: competitiondata/cifar-10-python/cifar-10-batches-py/test_batch  \n",
            "  inflating: competitiondata/cifar_test_nolabels.pkl  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Use this to upload your kaggle.json file\n",
        "\n",
        "# Make sure kaggle.json is in the location ~/.kaggle/kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c deep-learning-mini-project-spring-24-nyu\n",
        "!unzip deep-learning-mini-project-spring-24-nyu.zip -d competitiondata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gwhSAVlDCXhc"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUF5ls1H9Drf",
        "outputId": "6a9278ff-e6b0-4ee1-a6e7-a6eb071dca09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "           Dropout-4           [-1, 16, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           4,608\n",
            "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
            "              ReLU-7           [-1, 32, 32, 32]               0\n",
            "            Conv2d-8           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-9           [-1, 32, 32, 32]              64\n",
            "           Conv2d-10           [-1, 32, 32, 32]             512\n",
            "      BatchNorm2d-11           [-1, 32, 32, 32]              64\n",
            "             GELU-12           [-1, 32, 32, 32]               0\n",
            "    ResidualBlock-13           [-1, 32, 32, 32]               0\n",
            "           Conv2d-14           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-15           [-1, 32, 32, 32]              64\n",
            "             ReLU-16           [-1, 32, 32, 32]               0\n",
            "           Conv2d-17           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-18           [-1, 32, 32, 32]              64\n",
            "             GELU-19           [-1, 32, 32, 32]               0\n",
            "    ResidualBlock-20           [-1, 32, 32, 32]               0\n",
            "           Conv2d-21           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-22           [-1, 32, 32, 32]              64\n",
            "             ReLU-23           [-1, 32, 32, 32]               0\n",
            "           Conv2d-24           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-25           [-1, 32, 32, 32]              64\n",
            "             GELU-26           [-1, 32, 32, 32]               0\n",
            "    ResidualBlock-27           [-1, 32, 32, 32]               0\n",
            "          Dropout-28           [-1, 32, 32, 32]               0\n",
            "           Conv2d-29           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-30           [-1, 64, 16, 16]             128\n",
            "             ReLU-31           [-1, 64, 16, 16]               0\n",
            "           Conv2d-32           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-33           [-1, 64, 16, 16]             128\n",
            "           Conv2d-34           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-35           [-1, 64, 16, 16]             128\n",
            "             GELU-36           [-1, 64, 16, 16]               0\n",
            "    ResidualBlock-37           [-1, 64, 16, 16]               0\n",
            "           Conv2d-38           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-39           [-1, 64, 16, 16]             128\n",
            "             ReLU-40           [-1, 64, 16, 16]               0\n",
            "           Conv2d-41           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-42           [-1, 64, 16, 16]             128\n",
            "             GELU-43           [-1, 64, 16, 16]               0\n",
            "    ResidualBlock-44           [-1, 64, 16, 16]               0\n",
            "           Conv2d-45           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-46           [-1, 64, 16, 16]             128\n",
            "             ReLU-47           [-1, 64, 16, 16]               0\n",
            "           Conv2d-48           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-49           [-1, 64, 16, 16]             128\n",
            "             GELU-50           [-1, 64, 16, 16]               0\n",
            "    ResidualBlock-51           [-1, 64, 16, 16]               0\n",
            "           Conv2d-52           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-53           [-1, 64, 16, 16]             128\n",
            "             ReLU-54           [-1, 64, 16, 16]               0\n",
            "           Conv2d-55           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-56           [-1, 64, 16, 16]             128\n",
            "             GELU-57           [-1, 64, 16, 16]               0\n",
            "    ResidualBlock-58           [-1, 64, 16, 16]               0\n",
            "AdaptiveMaxPool2d-59           [-1, 64, 24, 24]               0\n",
            "           Conv2d-60          [-1, 115, 12, 12]          66,240\n",
            "      BatchNorm2d-61          [-1, 115, 12, 12]             230\n",
            "             ReLU-62          [-1, 115, 12, 12]               0\n",
            "           Conv2d-63          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-64          [-1, 115, 12, 12]             230\n",
            "           Conv2d-65          [-1, 115, 12, 12]           7,360\n",
            "      BatchNorm2d-66          [-1, 115, 12, 12]             230\n",
            "             GELU-67          [-1, 115, 12, 12]               0\n",
            "    ResidualBlock-68          [-1, 115, 12, 12]               0\n",
            "           Conv2d-69          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-70          [-1, 115, 12, 12]             230\n",
            "             ReLU-71          [-1, 115, 12, 12]               0\n",
            "           Conv2d-72          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-73          [-1, 115, 12, 12]             230\n",
            "             GELU-74          [-1, 115, 12, 12]               0\n",
            "    ResidualBlock-75          [-1, 115, 12, 12]               0\n",
            "           Conv2d-76          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-77          [-1, 115, 12, 12]             230\n",
            "             ReLU-78          [-1, 115, 12, 12]               0\n",
            "           Conv2d-79          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-80          [-1, 115, 12, 12]             230\n",
            "             GELU-81          [-1, 115, 12, 12]               0\n",
            "    ResidualBlock-82          [-1, 115, 12, 12]               0\n",
            "           Conv2d-83          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-84          [-1, 115, 12, 12]             230\n",
            "             ReLU-85          [-1, 115, 12, 12]               0\n",
            "           Conv2d-86          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-87          [-1, 115, 12, 12]             230\n",
            "             GELU-88          [-1, 115, 12, 12]               0\n",
            "    ResidualBlock-89          [-1, 115, 12, 12]               0\n",
            "           Conv2d-90          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-91          [-1, 115, 12, 12]             230\n",
            "             ReLU-92          [-1, 115, 12, 12]               0\n",
            "           Conv2d-93          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-94          [-1, 115, 12, 12]             230\n",
            "             GELU-95          [-1, 115, 12, 12]               0\n",
            "    ResidualBlock-96          [-1, 115, 12, 12]               0\n",
            "           Conv2d-97          [-1, 115, 12, 12]         119,025\n",
            "      BatchNorm2d-98          [-1, 115, 12, 12]             230\n",
            "             ReLU-99          [-1, 115, 12, 12]               0\n",
            "          Conv2d-100          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-101          [-1, 115, 12, 12]             230\n",
            "            GELU-102          [-1, 115, 12, 12]               0\n",
            "   ResidualBlock-103          [-1, 115, 12, 12]               0\n",
            "          Conv2d-104          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-105          [-1, 115, 12, 12]             230\n",
            "            ReLU-106          [-1, 115, 12, 12]               0\n",
            "          Conv2d-107          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-108          [-1, 115, 12, 12]             230\n",
            "            GELU-109          [-1, 115, 12, 12]               0\n",
            "   ResidualBlock-110          [-1, 115, 12, 12]               0\n",
            "          Conv2d-111          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-112          [-1, 115, 12, 12]             230\n",
            "            ReLU-113          [-1, 115, 12, 12]               0\n",
            "          Conv2d-114          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-115          [-1, 115, 12, 12]             230\n",
            "            GELU-116          [-1, 115, 12, 12]               0\n",
            "   ResidualBlock-117          [-1, 115, 12, 12]               0\n",
            "          Conv2d-118          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-119          [-1, 115, 12, 12]             230\n",
            "            ReLU-120          [-1, 115, 12, 12]               0\n",
            "          Conv2d-121          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-122          [-1, 115, 12, 12]             230\n",
            "            GELU-123          [-1, 115, 12, 12]               0\n",
            "   ResidualBlock-124          [-1, 115, 12, 12]               0\n",
            "          Conv2d-125          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-126          [-1, 115, 12, 12]             230\n",
            "            ReLU-127          [-1, 115, 12, 12]               0\n",
            "          Conv2d-128          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-129          [-1, 115, 12, 12]             230\n",
            "            GELU-130          [-1, 115, 12, 12]               0\n",
            "   ResidualBlock-131          [-1, 115, 12, 12]               0\n",
            "          Conv2d-132          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-133          [-1, 115, 12, 12]             230\n",
            "            ReLU-134          [-1, 115, 12, 12]               0\n",
            "          Conv2d-135          [-1, 115, 12, 12]         119,025\n",
            "     BatchNorm2d-136          [-1, 115, 12, 12]             230\n",
            "            GELU-137          [-1, 115, 12, 12]               0\n",
            "   ResidualBlock-138          [-1, 115, 12, 12]               0\n",
            "         Dropout-139          [-1, 115, 12, 12]               0\n",
            "          Conv2d-140            [-1, 256, 6, 6]         264,960\n",
            "     BatchNorm2d-141            [-1, 256, 6, 6]             512\n",
            "            ReLU-142            [-1, 256, 6, 6]               0\n",
            "          Conv2d-143            [-1, 256, 6, 6]         589,824\n",
            "     BatchNorm2d-144            [-1, 256, 6, 6]             512\n",
            "          Conv2d-145            [-1, 256, 6, 6]          29,440\n",
            "     BatchNorm2d-146            [-1, 256, 6, 6]             512\n",
            "            GELU-147            [-1, 256, 6, 6]               0\n",
            "   ResidualBlock-148            [-1, 256, 6, 6]               0\n",
            "          Conv2d-149            [-1, 256, 6, 6]         589,824\n",
            "     BatchNorm2d-150            [-1, 256, 6, 6]             512\n",
            "            ReLU-151            [-1, 256, 6, 6]               0\n",
            "          Conv2d-152            [-1, 256, 6, 6]         589,824\n",
            "     BatchNorm2d-153            [-1, 256, 6, 6]             512\n",
            "            GELU-154            [-1, 256, 6, 6]               0\n",
            "   ResidualBlock-155            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-156            [-1, 256, 3, 3]               0\n",
            "          Linear-157                   [-1, 10]          23,050\n",
            "================================================================\n",
            "Total params: 4,999,689\n",
            "Trainable params: 4,999,689\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 21.78\n",
            "Params size (MB): 19.07\n",
            "Estimated Total Size (MB): 40.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, padding=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, bias=False) # trying same padding\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.gelu = nn.GELU() # adding in a gelu layer for testing\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding, bias=False) # valid padding trying\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        identity = nn.AdaptiveAvgPool2d(out.size()[2])(identity)\n",
        "        out += identity\n",
        "        out = self.gelu(out) # trying out a gelu for one of the blocks\n",
        "\n",
        "        return out\n",
        "\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ModifiedResNet, self).__init__()\n",
        "        self.in_channels = 16 # number of output channels\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.dropout = nn.Dropout(0.432); # dropout layer probability\n",
        "        self.dropoutlow = nn.Dropout(0.287) # lower dropout prob\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.maxpool1 = nn.AdaptiveMaxPool2d(24)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 32, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 115, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2)\n",
        "        # Adjust the layer configuration to stay under 5 million parameters\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((3, 3))\n",
        "        self.fc = nn.Linear(256 * 3 * 3, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropoutlow(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.dropoutlow(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ModifiedResNet(ResidualBlock, [3, 4, 11, 2]).to('cuda')\n",
        "\n",
        "# Use torchsummary for a detailed summary and parameter count\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3x2ARAQ7LiV",
        "outputId": "2a57067e-5ef7-420e-8ed5-8ca678457031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43342713.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "#data loading\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "#testdata = unpickle('/content/competitiondata/cifar_test_nolabels.pkl')\n",
        "# Preprocess and load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, 4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Use the function to load the data\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "#testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "          #                             download=True, transform=None)\n",
        "#testloader = DataLoader(testdata, batch_size=128, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dymr51KO-NKC",
        "outputId": "a8c3ce0f-02d6-4e82-f8cf-feece15010d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#defining model, optimizer, regularization, hyperparameters\n",
        "\n",
        "# hyperparameters\n",
        "epochs = 200\n",
        "lr = 1e-4\n",
        "grad_accumulation = 3\n",
        "model_save = 5\n",
        "# use modified ResNet model\n",
        "GPU = True\n",
        "\n",
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.1)\n",
        "scaler = GradScaler(enabled=GPU)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "checkpoint = torch.load('model.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "kr3vZh8k-Z0B",
        "outputId": "2319c427-5dc6-491a-ea4d-849cd21cf9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1] loss: 0.001\n",
            "[1, 201] loss: 0.206\n",
            "just saved model incase something goes wrong\n",
            "finished epoch 1 in 47.0 seconds\n",
            "[2, 1] loss: 0.001\n",
            "[2, 201] loss: 0.208\n",
            "finished epoch 2 in 47.0 seconds\n",
            "[3, 1] loss: 0.001\n",
            "[3, 201] loss: 0.205\n",
            "finished epoch 3 in 46.0 seconds\n",
            "[4, 1] loss: 0.001\n",
            "[4, 201] loss: 0.209\n",
            "finished epoch 4 in 46.0 seconds\n",
            "[5, 1] loss: 0.001\n",
            "[5, 201] loss: 0.208\n",
            "finished epoch 5 in 46.0 seconds\n",
            "[6, 1] loss: 0.001\n",
            "[6, 201] loss: 0.208\n",
            "just saved model incase something goes wrong\n",
            "finished epoch 6 in 47.0 seconds\n",
            "[7, 1] loss: 0.001\n",
            "[7, 201] loss: 0.208\n",
            "finished epoch 7 in 46.0 seconds\n",
            "[8, 1] loss: 0.001\n",
            "[8, 201] loss: 0.206\n",
            "finished epoch 8 in 49.0 seconds\n",
            "[9, 1] loss: 0.001\n",
            "[9, 201] loss: 0.206\n",
            "finished epoch 9 in 46.0 seconds\n",
            "[10, 1] loss: 0.001\n",
            "[10, 201] loss: 0.203\n",
            "finished epoch 10 in 46.0 seconds\n",
            "[11, 1] loss: 0.001\n",
            "[11, 201] loss: 0.210\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-be346fa99465>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print loss after 200 iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training model\n",
        "import time\n",
        "\n",
        "# train model\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
        "\n",
        "        # smap for speeding up training\n",
        "        with autocast(enabled=GPU):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        # grad accumulation\n",
        "        if (i + 1) % grad_accumulation == 0:\n",
        "          scaler.step(optimizer)\n",
        "          scaler.update()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 0:    # print loss after 200 iters\n",
        "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch % model_save == 0:\n",
        "        print(\"just saved model incase something goes wrong\")\n",
        "        model.cpu()  # Move model to CPU\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'scaler': scaler.state_dict(),\n",
        "            }, \"model.pth\")\n",
        "        model.cuda()  # Move model back to GPU if further training is needed\n",
        "\n",
        "\n",
        "    end_time = (time.time() - start_time ) // 1\n",
        "    print(f\"finished epoch {epoch + 1} in {end_time} seconds\" )\n",
        "\n",
        "print('Finished Training')\n",
        "print(\"just saved final model incase something goes wrong\")\n",
        "model.cpu()  # Move model to CPU\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'scaler': scaler.state_dict(),\n",
        "            }, \"model.pth\")\n",
        "model.cuda()  # Move model back to GPU if further training is needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0cfvGyH_Eor",
        "outputId": "c259e2c9-017b-4a9b-bca5-113009d9a52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# testing data code adopted from https://github.com/hzhao20/DLMiniproject/blob/main/GenerateCSV.py.\n",
        "\"\"\"\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Y7hJP7qXUYC-K7YD40kiqYj4Hz-TRluh\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# unpickle function\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "# load\n",
        "test_data_dict = unpickle('/content/competitiondata/cifar_test_nolabels.pkl')\n",
        "test_images = test_data_dict[b'data']\n",
        "test_ids = test_data_dict[b'ids']\n",
        "\n",
        "# transform\n",
        "test_images = test_images.reshape(len(test_images), 3, 32, 32).transpose(0, 2, 3, 1)  # 从CHW转换为HWC\n",
        "\n",
        "# preprocess\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 根据模型训练时的配置调整\n",
        "])\n",
        "\n",
        "test_images = torch.stack([transform(img) for img in test_images])\n",
        "\n",
        "# data loader\n",
        "test_loader = DataLoader(TensorDataset(test_images, torch.tensor(test_ids)), batch_size=64, shuffle=False)\n",
        "\n",
        "# load model\n",
        "model = model.to(device) # prolly on cuda\n",
        "model.eval()\n",
        "\n",
        "# predict\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "# generate CSV\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'Labels': predicted_labels\n",
        "})\n",
        "\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
